{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708a7622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Could not find a local data folder. Expected ./data/Train and ./data/Test",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_185/2473244521.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Could not find a local data folder. Expected ./data/Train and ./data/Test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mDATA_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_data_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# If your structure is data/<dataset_name>/(Train,Test), set DATASET_SUBDIR to that folder name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_185/2473244521.py\u001b[0m in \u001b[0;36mfind_data_dir\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Could not find a local data folder. Expected ./data/Train and ./data/Test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mDATA_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_data_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Could not find a local data folder. Expected ./data/Train and ./data/Test"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "# ========================== 1. CONFIG (LOCAL) ==========================\n",
    "SEED = 42\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "\n",
    "def find_data_dir() -> Path:\n",
    "    \"\"\"Locate repo-local data folder robustly.\"\"\"\n",
    "    candidates = [\n",
    "        Path.cwd() / 'data',\n",
    "        Path.cwd().parent / 'data',\n",
    "        Path.cwd().parent.parent / 'data',\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        if (c / 'Train').exists() and (c / 'Test').exists():\n",
    "            return c\n",
    "    # fallback: accept data/ even if Train/Test are nested under a single dataset folder\n",
    "    for c in candidates:\n",
    "        if c.exists() and c.is_dir():\n",
    "            return c\n",
    "    raise FileNotFoundError('Could not find a local data folder. Expected ./data/Train and ./data/Test')\n",
    "\n",
    "DATA_DIR = find_data_dir()\n",
    "\n",
    "# If your structure is data/<dataset_name>/(Train,Test), set DATASET_SUBDIR to that folder name\n",
    "DATASET_SUBDIR = None  # e.g. 'Skin cancer ISIC The International Skin Imaging Collaboration'\n",
    "\n",
    "def _is_train_name(name: str) -> bool:\n",
    "    n = name.strip().lower()\n",
    "    return n == 'train' or n.startswith('train') or n in {'training', 'trainset', 'train_set'}\n",
    "\n",
    "def _is_test_name(name: str) -> bool:\n",
    "    n = name.strip().lower()\n",
    "    return n == 'test' or n.startswith('test') or n in {'testset', 'test_set'}\n",
    "\n",
    "def _find_train_test_pair(root: Path):\n",
    "    \"\"\"Return (base_dir, train_dir, test_dir) if found, else None.\"\"\"\n",
    "    if not root.exists() or not root.is_dir():\n",
    "        return None\n",
    "\n",
    "    children = [p for p in root.iterdir() if p.is_dir()]\n",
    "    train_dir = next((p for p in children if _is_train_name(p.name)), None)\n",
    "    test_dir = next((p for p in children if _is_test_name(p.name)), None)\n",
    "    if train_dir and test_dir:\n",
    "        return root, train_dir, test_dir\n",
    "\n",
    "    data_dir = next((p for p in children if p.name.strip().lower() == 'data'), None)\n",
    "    if data_dir:\n",
    "        return _find_train_test_pair(data_dir)\n",
    "\n",
    "    return None\n",
    "\n",
    "base = DATA_DIR\n",
    "if isinstance(DATASET_SUBDIR, str) and DATASET_SUBDIR.strip():\n",
    "    base = DATA_DIR / DATASET_SUBDIR.strip()\n",
    "\n",
    "pair = _find_train_test_pair(base)\n",
    "if not pair:\n",
    "    # deep search: find sibling Train/Test under any subfolder\n",
    "    train_candidates = [p for p in base.glob('**/*') if p.is_dir() and _is_train_name(p.name)]\n",
    "    test_candidates = [p for p in base.glob('**/*') if p.is_dir() and _is_test_name(p.name)]\n",
    "    found_parent = None\n",
    "    for tr in train_candidates:\n",
    "        sib = next((s for s in tr.parent.iterdir() if s.is_dir() and _is_test_name(s.name)), None)\n",
    "        if sib:\n",
    "            found_parent = tr.parent\n",
    "            break\n",
    "    if found_parent:\n",
    "        pair = _find_train_test_pair(found_parent)\n",
    "\n",
    "if not pair:\n",
    "    raise FileNotFoundError(f'Could not find Train/Test under: {base}. Expected Train/ and Test/ with class subfolders.')\n",
    "\n",
    "BASE_DATA_DIR, TRAIN_DIR, TEST_DIR = pair\n",
    "print('Detected BASE_DATA_DIR:', BASE_DATA_DIR)\n",
    "print('Train dir:', TRAIN_DIR)\n",
    "print('Test dir :', TEST_DIR)\n",
    "\n",
    "NUM_CLASSES = 9\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "T_MAX = 20\n",
    "OVERSAMPLE_FACTOR = 5\n",
    "NUM_WORKERS = 2 if torch.cuda.is_available() else 0\n",
    "PIN_MEMORY = True if torch.cuda.is_available() else False\n",
    "PATIENCE = 6\n",
    "USE_FOCAL = True\n",
    "\n",
    "BASE_PATH = Path('runs') / 'VGG16_Results'\n",
    "LOG_DIR = BASE_PATH / 'logs'\n",
    "CKPT_DIR = BASE_PATH / 'checkpoints'\n",
    "BEST_DIR = BASE_PATH / 'best_model'\n",
    "RESULT_DIR = BASE_PATH / 'results'\n",
    "\n",
    "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "BEST_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LOG_CSV = LOG_DIR / 'training_log.csv'\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# ========================== 2. LABEL MAP ==========================\n",
    "label_map = {\n",
    "    0: 'actinic keratosis',\n",
    "    1: 'basal cell carcinoma',\n",
    "    2: 'dermatofibroma',\n",
    "    3: 'melanoma',\n",
    "    4: 'nevus',\n",
    "    5: 'pigmented benign keratosis',\n",
    "    6: 'seborrheic keratosis',\n",
    "    7: 'squamous cell carcinoma',\n",
    "    8: 'vascular lesion',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfd7d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 3. RAW DATASET ==========================\n",
    "train_dataset_raw = datasets.ImageFolder(str(TRAIN_DIR))\n",
    "test_dataset = datasets.ImageFolder(str(TEST_DIR))\n",
    "\n",
    "print('Train samples:', len(train_dataset_raw))\n",
    "print('Test  samples:', len(test_dataset))\n",
    "print('Class folders (ImageFolder):', train_dataset_raw.classes)\n",
    "\n",
    "# ========================== 4. TRANSFORMS / AUGMENT ==========================\n",
    "class RandomAugmentationPerImage:\n",
    "    def __init__(self):\n",
    "        self.augmentations = [\n",
    "            transforms.RandomHorizontalFlip(p=0.5)\n",
    "            ,transforms.RandomVerticalFlip(p=0.5)\n",
    "            ,transforms.RandomRotation(40)\n",
    "            ,transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2)\n",
    "        ]\n",
    "        self.resize = transforms.Resize((224, 224))\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = self.resize(img)\n",
    "        for aug in self.augmentations:\n",
    "            if torch.rand(1) < 0.5:\n",
    "                img = aug(img)\n",
    "        img = self.to_tensor(img)\n",
    "        img = self.normalize(img)\n",
    "        return img\n",
    "\n",
    "transform_train = RandomAugmentationPerImage()\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53964b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 5. PLOT SAMPLE & CLASS DISTRIBUTION ==========================\n",
    "def plot_class_distribution(labels, label_map, title='Class Distribution'):\n",
    "    counter = Counter(labels)\n",
    "    total = sum(counter.values())\n",
    "    print(f'--- {title} ---')\n",
    "    for i in range(len(label_map)):\n",
    "        count = counter.get(i, 0)\n",
    "        print(f'{i} ({label_map[i]}): {count} samples | {count / total * 100:.2f}%')\n",
    "    counts = [counter.get(i, 0) for i in range(len(label_map))]\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.pie(counts, labels=[label_map[i] for i in range(len(label_map))], autopct='%1.1f%%', startangle=140)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "original_labels = [label for _, label in train_dataset_raw.imgs]\n",
    "plot_class_distribution(original_labels, label_map, title='Original Train Distribution')\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 4))\n",
    "for i, ax in enumerate(axes):\n",
    "    img, label = train_dataset_raw[random.randint(0, len(train_dataset_raw) - 1)]\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(label_map[label])\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Sample Original Images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc8c763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 6. OVERSAMPLING ==========================\n",
    "targets = [train_dataset_raw.imgs[i][1] for i in range(len(train_dataset_raw.imgs))]\n",
    "class_counts = Counter(targets)\n",
    "max_count = max(class_counts.values()) * OVERSAMPLE_FACTOR\n",
    "weights_per_class = {cls: max_count / count for cls, count in class_counts.items()}\n",
    "sample_weights = np.array([weights_per_class[t] for t in targets])\n",
    "indices = np.random.choice(\n",
    "    len(targets),\n",
    "    size=len(targets) * OVERSAMPLE_FACTOR,\n",
    "    replace=True,\n",
    "    p=sample_weights / sample_weights.sum(),\n",
    ")\n",
    "\n",
    "class OversampledDataset(Dataset):\n",
    "    def __init__(self, base_dataset, indices, transform=None):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.indices = indices\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.base_dataset[self.indices[idx]]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "train_dataset_full = OversampledDataset(train_dataset_raw, indices, transform=transform_train)\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 4))\n",
    "for i, ax in enumerate(axes):\n",
    "    img, label = train_dataset_full[random.randint(0, len(train_dataset_full) - 1)]\n",
    "    img_np = img.permute(1, 2, 0).numpy()\n",
    "    denom = (img_np.max() - img_np.min())\n",
    "    img_np = (img_np - img_np.min()) / (denom if denom != 0 else 1.0)\n",
    "    ax.imshow(img_np)\n",
    "    ax.set_title(label_map[label])\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Sample Augmented Images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaebb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 7. SPLIT TRAIN / VAL ==========================\n",
    "oversampled_imgs = [train_dataset_raw.imgs[i] for i in indices]\n",
    "paths, labels = zip(*oversampled_imgs)\n",
    "paths = np.array(paths)\n",
    "labels = np.array(labels)\n",
    "\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    paths, labels, test_size=0.3, stratify=labels, random_state=SEED\n",
    ")\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None):\n",
    "        self.paths = np.array(paths)\n",
    "        self.labels = np.array(labels)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx]).convert('RGB')\n",
    "        label = int(self.labels[idx])\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    CustomDataset(train_paths, train_labels, transform=transform_train),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    CustomDataset(val_paths, val_labels, transform=transform_val),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    ")\n",
    "\n",
    "test_paths = [p for p, _ in test_dataset.imgs]\n",
    "test_labels = [l for _, l in test_dataset.imgs]\n",
    "test_loader = DataLoader(\n",
    "    CustomDataset(test_paths, test_labels, transform=transform_val),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    ")\n",
    "\n",
    "plot_class_distribution(train_labels, label_map, title='Train Distribution After Oversampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a48e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 8. CLASS WEIGHTS & LOSS ==========================\n",
    "train_labels_for_weights = train_labels.astype(int)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_labels_for_weights),\n",
    "    y=train_labels_for_weights,\n",
    ")\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, weight=None, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce = nn.CrossEntropyLoss(weight=self.weight, reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-ce)\n",
    "        loss = ((1 - pt) ** self.gamma) * ce\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        if self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        return loss\n",
    "\n",
    "criterion = FocalLoss(gamma=2.0, weight=class_weights) if USE_FOCAL else nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# ========================== 9. EARLY STOPPING ==========================\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_f1 = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, f1):\n",
    "        if self.best_f1 is None:\n",
    "            self.best_f1 = f1\n",
    "            return\n",
    "        if f1 < self.best_f1 + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_f1 = f1\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7722de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 10. VGG16 MODEL ==========================\n",
    "# Local setup: you can use pretrained weights (downloads if not cached).\n",
    "# If you are offline and it fails, set PRETRAINED = False.\n",
    "\n",
    "PRETRAINED = True\n",
    "\n",
    "class VGG16Model(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES, pretrained=PRETRAINED):\n",
    "        super().__init__()\n",
    "        if pretrained:\n",
    "            try:\n",
    "                weights = models.VGG16_Weights.DEFAULT\n",
    "                self.vgg16 = models.vgg16(weights=weights)\n",
    "                print('Loaded ImageNet pretrained weights (VGG16).')\n",
    "            except Exception as e:\n",
    "                print('Warning: failed to load pretrained weights; using random init. Error:', repr(e))\n",
    "                self.vgg16 = models.vgg16(weights=None)\n",
    "        else:\n",
    "            self.vgg16 = models.vgg16(weights=None)\n",
    "\n",
    "        for param in self.vgg16.features[:20].parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        num_features = self.vgg16.classifier[6].in_features\n",
    "        self.vgg16.classifier[6] = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.vgg16(x)\n",
    "\n",
    "model = VGG16Model(num_classes=NUM_CLASSES).to(device)\n",
    "print(f'Model loaded on {device}')\n",
    "print(f'Total parameters: {sum(p.numel() for p in model.parameters())}')\n",
    "print(f'Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b27921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 11. TRAIN / EVAL FUNCTIONS ==========================\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device, epoch):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    loop = tqdm(enumerate(loader), total=len(loader), desc=f'Epoch {epoch} [TRAIN]')\n",
    "    for i, (imgs, labels) in loop:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        preds = outputs.argmax(1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        loop.set_postfix(loss=running_loss / (i + 1), acc=correct / total)\n",
    "    return running_loss / len(loader), correct / total\n",
    "\n",
    "def eval_one_epoch(model, loader, criterion, device, epoch):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(enumerate(loader), total=len(loader), desc=f'Epoch {epoch} [VAL]')\n",
    "        for i, (imgs, labels) in loop:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            preds = outputs.argmax(1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            loop.set_postfix(loss=running_loss / (i + 1), acc=correct / total)\n",
    "    macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    return running_loss / len(loader), correct / total, macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1307c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 12. TRAINING LOOP ==========================\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_MAX)\n",
    "early_stopper = EarlyStopping(patience=PATIENCE)\n",
    "\n",
    "best_f1 = 0.0\n",
    "best_epoch = 0\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': [], 'f1': []}\n",
    "\n",
    "with open(LOG_CSV, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['epoch', 'train_loss', 'train_acc', 'val_loss', 'val_acc', 'macro_f1'])\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device, epoch)\n",
    "    val_loss, val_acc, val_macro_f1 = eval_one_epoch(model, val_loader, criterion, device, epoch)\n",
    "\n",
    "    scheduler.step()\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['f1'].append(val_macro_f1)\n",
    "\n",
    "    with open(LOG_CSV, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([epoch, train_loss, train_acc, val_loss, val_acc, val_macro_f1])\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        ckpt_path = CKPT_DIR / f'model_epoch_{epoch}.pt'\n",
    "        torch.save(model.state_dict(), ckpt_path)\n",
    "        print(' Saved checkpoint:', ckpt_path)\n",
    "\n",
    "    if val_macro_f1 > best_f1:\n",
    "        best_f1 = val_macro_f1\n",
    "        best_epoch = epoch\n",
    "        best_path = BEST_DIR / 'best_model_vgg16.pt'\n",
    "        torch.save(model.state_dict(), best_path)\n",
    "        print(f' Best model updated at epoch {epoch} | F1={best_f1:.4f}')\n",
    "\n",
    "    print(\n",
    "        f'Epoch {epoch}/{NUM_EPOCHS} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | '\n",
    "        f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | Macro F1: {val_macro_f1:.4f}'\n",
    "    )\n",
    "\n",
    "    early_stopper(val_macro_f1)\n",
    "    if early_stopper.early_stop:\n",
    "        print('>>> Early stopping triggered. Stopping training.')\n",
    "        break\n",
    "\n",
    "print('\\nTraining completed. Best Epoch =', best_epoch, '| Best F1 =', best_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8242f962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 13. PLOT METRICS ==========================\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history['train_acc'], label='Train Acc')\n",
    "plt.plot(history['val_acc'], label='Val Acc')\n",
    "plt.title('Accuracy Curve')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history['f1'], label='Macro F1')\n",
    "plt.title('Macro F1 Curve')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plot_path = RESULT_DIR / 'training_curves_vgg16.png'\n",
    "plt.savefig(plot_path)\n",
    "print('Saved:', plot_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c5fd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 14. CONFUSION MATRIX & TEST ==========================\n",
    "best_model_path = BEST_DIR / 'best_model_vgg16.pt'\n",
    "if best_model_path.exists():\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location='cpu'))\n",
    "    model.to(device)\n",
    "    print('Loaded best model from', best_model_path)\n",
    "else:\n",
    "    print('Best model not found yet at:', best_model_path)\n",
    "\n",
    "def plot_confusion(loader, title, save_path):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            preds = outputs.argmax(1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=label_map.values(), yticklabels=label_map.values(), cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True')\n",
    "    plt.xlabel('Pred')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    print('Saved:', save_path)\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion(val_loader, 'Validation Confusion Matrix (VGG16)', RESULT_DIR / 'val_conf_matrix_vgg16.png')\n",
    "plot_confusion(test_loader, 'Test Confusion Matrix (VGG16)', RESULT_DIR / 'test_conf_matrix_vgg16.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b530f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 15. DETAILED EVALUATION ==========================\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "        preds = outputs.argmax(1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "\n",
    "report = classification_report(all_labels, all_preds, target_names=list(label_map.values()))\n",
    "print('\\nClassification Report (VGG16):\\n', report)\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=label_map.values(), yticklabels=label_map.values(), cmap='Blues')\n",
    "plt.title('Confusion Matrix (Validation - VGG16)')\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Pred')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "counter = Counter(all_labels)\n",
    "print('\\nNumber of samples per class in validation set:')\n",
    "for i, name in label_map.items():\n",
    "    print(f'{name}: {counter[i]}')\n",
    "\n",
    "y_test_bin = label_binarize(all_labels, classes=list(range(NUM_CLASSES)))\n",
    "y_score_bin = label_binarize(all_preds, classes=list(range(NUM_CLASSES)))\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "for i in range(NUM_CLASSES):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score_bin[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{label_map[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve per Class (Validation - VGG16)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (ML Training)",
   "language": "python",
   "name": "venv-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
