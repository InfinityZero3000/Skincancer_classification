{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9a066b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPU requested but torch_xla is not available -> TPU is likely NOT enabled in Kaggle settings.\n",
      "torch_xla import error: ModuleNotFoundError(\"No module named 'torch_xla'\")\n",
      "Device: cpu\n",
      "Note: CPU is being used because TPU is unavailable and CUDA is not available.\n",
      "\n",
      "--- Debug: /kaggle/input contents ---\n",
      "Listing /kaggle/input: 1 entries\n",
      " - skin-cancer9-classesisic/\n",
      "\n",
      "--- Debug: dataset folder ---\n",
      "Dataset dir: /kaggle/input/skin-cancer9-classesisic\n",
      "Listing /kaggle/input/skin-cancer9-classesisic: 2 entries\n",
      " - Skin cancer ISIC The International Skin Imaging Collaboration/\n",
      " - skin cancer isic the international skin imaging collaboration/\n",
      "\n",
      "Deep searching for Train/Test under /kaggle/input/skin-cancer9-classesisic\n",
      "Found train-like dirs: 2\n",
      " - /kaggle/input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Train\n",
      " - /kaggle/input/skin-cancer9-classesisic/skin cancer isic the international skin imaging collaboration/Skin cancer ISIC The International Skin Imaging Collaboration/Train\n",
      "Found test-like dirs : 2\n",
      " - /kaggle/input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Test\n",
      " - /kaggle/input/skin-cancer9-classesisic/skin cancer isic the international skin imaging collaboration/Skin cancer ISIC The International Skin Imaging Collaboration/Test\n",
      "\n",
      "Detected BASE_DATA_DIR: /kaggle/input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration\n",
      "Train dir: /kaggle/input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Train\n",
      "Test dir : /kaggle/input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "from types import ModuleType\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "# ========================== 1. CONFIG (KAGGLE) ==========================\n",
    "SEED = 42\n",
    "\n",
    "# Toggle TPU usage. If another cell already set USE_TPU, keep that value.\n",
    "USE_TPU = bool(globals().get('USE_TPU', True))\n",
    "\n",
    "# Prefer TPU (torch_xla) if available; else CUDA; else CPU\n",
    "IS_XLA = False\n",
    "xm: Optional[ModuleType] = None\n",
    "\n",
    "if USE_TPU:\n",
    "    try:\n",
    "        import torch_xla.core.xla_model as xla_model  # type: ignore\n",
    "        xm = xla_model\n",
    "        IS_XLA = True\n",
    "    except Exception as e:\n",
    "        IS_XLA = False\n",
    "        xm = None\n",
    "        print('TPU requested but torch_xla is not available -> TPU is likely NOT enabled in Kaggle settings.')\n",
    "        print('torch_xla import error:', repr(e))\n",
    "\n",
    "if IS_XLA and xm is not None:\n",
    "    device = xm.xla_device()\n",
    "    print('Device: xla (TPU)')\n",
    "else:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('Device:', device)\n",
    "    if str(device) == 'cpu':\n",
    "        print('Note: CPU is being used because TPU is unavailable and CUDA is not available.')\n",
    "\n",
    "IS_CUDA = (not IS_XLA) and torch.cuda.is_available()\n",
    "\n",
    "IS_CUDA = (not IS_XLA) and torch.cuda.is_available()\n",
    "\n",
    "# Kaggle paths\n",
    "KAGGLE_INPUT = Path('/kaggle/input')\n",
    "KAGGLE_WORKING = Path('/kaggle/working')\n",
    "\n",
    "# Optional: if your dataset is attached but the auto-detect fails, set this to the dataset subfolder name.\n",
    "# Example: DATASET_SUBDIR = 'your-dataset-slug'  (the folder directly under /kaggle/input)\n",
    "DATASET_SUBDIR = None  # or a string\n",
    "\n",
    "def _safe_listdir(path: Path, limit: int = 100):\n",
    "    try:\n",
    "        items = sorted(list(path.iterdir()))\n",
    "    except Exception as e:\n",
    "        print(f'Could not list {path}: {e}')\n",
    "        return []\n",
    "    if len(items) > limit:\n",
    "        print(f'Listing {path}: showing first {limit} of {len(items)} entries')\n",
    "        items = items[:limit]\n",
    "    else:\n",
    "        print(f'Listing {path}: {len(items)} entries')\n",
    "    for p in items:\n",
    "        suffix = '/' if p.is_dir() else ''\n",
    "        print(' -', p.name + suffix)\n",
    "    return items\n",
    "\n",
    "def _is_train_name(name: str) -> bool:\n",
    "    n = name.strip().lower()\n",
    "    return n == 'train' or n.startswith('train') or n in {'training', 'trainset', 'train_set'}\n",
    "\n",
    "def _is_test_name(name: str) -> bool:\n",
    "    n = name.strip().lower()\n",
    "    return n == 'test' or n.startswith('test') or n in {'testset', 'test_set'}\n",
    "\n",
    "def _find_train_test_pair(root: Path):\n",
    "    \"\"\"Return (base_dir, train_dir, test_dir) if found, else None.\"\"\"\n",
    "    if not root.exists() or not root.is_dir():\n",
    "        return None\n",
    "\n",
    "    # 1) direct children, flexible train/test naming\n",
    "    children = [p for p in root.iterdir() if p.is_dir()]\n",
    "    train_dir = next((p for p in children if _is_train_name(p.name)), None)\n",
    "    test_dir = next((p for p in children if _is_test_name(p.name)), None)\n",
    "    if train_dir and test_dir:\n",
    "        return root, train_dir, test_dir\n",
    "\n",
    "    # 2) common nesting: root/data/(Train,Test)\n",
    "    data_dir = next((p for p in children if p.name.strip().lower() == 'data'), None)\n",
    "    if data_dir:\n",
    "        return _find_train_test_pair(data_dir)\n",
    "\n",
    "    return None\n",
    "\n",
    "def _maybe_unzip_here(dataset_dir: Path, extract_to: Path) -> Path | None:\n",
    "    \"\"\"If dataset_dir contains zip(s), unzip to extract_to and return extract_to; else None.\"\"\"\n",
    "    if not dataset_dir.exists() or not dataset_dir.is_dir():\n",
    "        return None\n",
    "    zips = sorted([p for p in dataset_dir.glob('*.zip') if p.is_file()])\n",
    "    if not zips:\n",
    "        return None\n",
    "\n",
    "    extract_to.mkdir(parents=True, exist_ok=True)\n",
    "    print(f'Found {len(zips)} zip file(s). Extracting to: {extract_to}')\n",
    "    for zp in zips:\n",
    "        print(' - extracting', zp.name)\n",
    "        with zipfile.ZipFile(zp, 'r') as zf:\n",
    "            zf.extractall(extract_to)\n",
    "    return extract_to\n",
    "\n",
    "def find_data_root_kaggle(input_root: Path) -> Path:\n",
    "    \"\"\"Find a folder that contains Train/ and Test/ (robust detection; supports zipped datasets).\"\"\"\n",
    "    if not input_root.exists():\n",
    "        raise FileNotFoundError(f'Kaggle input folder not found: {input_root}')\n",
    "\n",
    "    print('\\n--- Debug: /kaggle/input contents ---')\n",
    "    _safe_listdir(input_root, limit=200)\n",
    "\n",
    "    dataset_dirs = [p for p in input_root.iterdir() if p.is_dir()]\n",
    "    if not dataset_dirs:\n",
    "        raise FileNotFoundError('No dataset folders found under /kaggle/input. Please use Add data in Kaggle.')\n",
    "\n",
    "    # If user specifies a dataset subdir, try it first.\n",
    "    if isinstance(DATASET_SUBDIR, str) and DATASET_SUBDIR.strip():\n",
    "        dataset_dirs = [input_root / DATASET_SUBDIR.strip()]\n",
    "\n",
    "    # Try each dataset folder\n",
    "    for dataset_dir in sorted(dataset_dirs):\n",
    "        print('\\n--- Debug: dataset folder ---')\n",
    "        print('Dataset dir:', dataset_dir)\n",
    "        _safe_listdir(dataset_dir, limit=200)\n",
    "\n",
    "        # 1) Train/Test present directly or under data/\n",
    "        pair = _find_train_test_pair(dataset_dir)\n",
    "        if pair:\n",
    "            base_dir, _, _ = pair\n",
    "            return base_dir\n",
    "\n",
    "        # 2) If there are zip files, unzip to working and try again\n",
    "        extracted = _maybe_unzip_here(dataset_dir, KAGGLE_WORKING / 'dataset_unzipped')\n",
    "        if extracted:\n",
    "            print('\\n--- Debug: extracted folder (top-level) ---')\n",
    "            _safe_listdir(extracted, limit=200)\n",
    "            pair = _find_train_test_pair(extracted)\n",
    "            if pair:\n",
    "                base_dir, _, _ = pair\n",
    "                return base_dir\n",
    "\n",
    "        # 3) Deep search for folders that look like train/test\n",
    "        print('\\nDeep searching for Train/Test under', dataset_dir)\n",
    "        train_candidates = []\n",
    "        test_candidates = []\n",
    "        for p in dataset_dir.glob('**/*'):\n",
    "            if p.is_dir():\n",
    "                if _is_train_name(p.name):\n",
    "                    train_candidates.append(p)\n",
    "                elif _is_test_name(p.name):\n",
    "                    test_candidates.append(p)\n",
    "        if train_candidates or test_candidates:\n",
    "            print('Found train-like dirs:', min(len(train_candidates), 20))\n",
    "            for p in train_candidates[:20]:\n",
    "                print(' -', p)\n",
    "            print('Found test-like dirs :', min(len(test_candidates), 20))\n",
    "            for p in test_candidates[:20]:\n",
    "                print(' -', p)\n",
    "\n",
    "        # Match sibling train/test under same parent\n",
    "        for train_path in train_candidates:\n",
    "            parent = train_path.parent\n",
    "            siblings = [s for s in parent.iterdir() if s.is_dir()]\n",
    "            sib_test = next((s for s in siblings if _is_test_name(s.name)), None)\n",
    "            if sib_test:\n",
    "                return parent\n",
    "\n",
    "        # If we extracted, also deep-search there\n",
    "        if extracted:\n",
    "            print('\\nDeep searching for Train/Test under extracted', extracted)\n",
    "            train_candidates = []\n",
    "            test_candidates = []\n",
    "            for p in extracted.glob('**/*'):\n",
    "                if p.is_dir():\n",
    "                    if _is_train_name(p.name):\n",
    "                        train_candidates.append(p)\n",
    "                    elif _is_test_name(p.name):\n",
    "                        test_candidates.append(p)\n",
    "            for train_path in train_candidates:\n",
    "                parent = train_path.parent\n",
    "                siblings = [s for s in parent.iterdir() if s.is_dir()]\n",
    "                sib_test = next((s for s in siblings if _is_test_name(s.name)), None)\n",
    "                if sib_test:\n",
    "                    return parent\n",
    "\n",
    "    found_names = [p.name for p in dataset_dirs]\n",
    "    raise FileNotFoundError(\n",
    "        'Could not find Train/ and Test/ under /kaggle/input. '\n",
    "        'Your attached dataset folder likely does not contain the image folders yet. '\n",
    "        'Please attach the dataset that includes Train/ and Test/ with class subfolders. '\n",
    "        f'Found dataset folders: {found_names}'\n",
    "    )\n",
    "\n",
    "BASE_DATA_DIR = find_data_root_kaggle(KAGGLE_INPUT)\n",
    "pair = _find_train_test_pair(BASE_DATA_DIR)\n",
    "if not pair:\n",
    "    raise FileNotFoundError(f'Internal error: BASE_DATA_DIR has no Train/Test: {BASE_DATA_DIR}')\n",
    "_, TRAIN_DIR, TEST_DIR = pair\n",
    "\n",
    "print('\\nDetected BASE_DATA_DIR:', BASE_DATA_DIR)\n",
    "print('Train dir:', TRAIN_DIR)\n",
    "print('Test dir :', TEST_DIR)\n",
    "\n",
    "NUM_CLASSES = 9\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 5e-4\n",
    "T_MAX = 20\n",
    "OVERSAMPLE_FACTOR = 5\n",
    "\n",
    "# DataLoader settings: XLA is picky; keep workers=0 and pin_memory=False on TPU\n",
    "NUM_WORKERS = 0 if IS_XLA else (2 if IS_CUDA else 0)\n",
    "PIN_MEMORY = True if IS_CUDA else False\n",
    "PATIENCE = 6\n",
    "USE_FOCAL = True\n",
    "\n",
    "BASE_PATH = KAGGLE_WORKING / 'DenseNet121_Results'\n",
    "LOG_DIR = BASE_PATH / 'logs'\n",
    "CKPT_DIR = BASE_PATH / 'checkpoints'\n",
    "BEST_DIR = BASE_PATH / 'best_model'\n",
    "RESULT_DIR = BASE_PATH / 'results'\n",
    "\n",
    "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "BEST_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LOG_CSV = LOG_DIR / 'training_log.csv'\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# ========================== 2. LABEL MAP ==========================\n",
    "label_map = {\n",
    "    0: 'actinic keratosis',\n",
    "    1: 'basal cell carcinoma',\n",
    "    2: 'dermatofibroma',\n",
    "    3: 'melanoma',\n",
    "    4: 'nevus',\n",
    "    5: 'pigmented benign keratosis',\n",
    "    6: 'seborrheic keratosis',\n",
    "    7: 'squamous cell carcinoma',\n",
    "    8: 'vascular lesion',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ec88a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 2239\n",
      "Test  samples: 118\n",
      "Class folders (ImageFolder): ['actinic keratosis', 'basal cell carcinoma', 'dermatofibroma', 'melanoma', 'nevus', 'pigmented benign keratosis', 'seborrheic keratosis', 'squamous cell carcinoma', 'vascular lesion']\n"
     ]
    }
   ],
   "source": [
    "# ========================== 3. RAW DATASET ==========================\n",
    "train_dataset_raw = datasets.ImageFolder(str(TRAIN_DIR))\n",
    "test_dataset = datasets.ImageFolder(str(TEST_DIR))\n",
    "\n",
    "print('Train samples:', len(train_dataset_raw))\n",
    "print('Test  samples:', len(test_dataset))\n",
    "print('Class folders (ImageFolder):', train_dataset_raw.classes)\n",
    "\n",
    "# ========================== 4. TRANSFORMS / AUGMENT ==========================\n",
    "class RandomAugmentationPerImage:\n",
    "    def __init__(self):\n",
    "        self.augmentations = [\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.RandomRotation(40),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        ]\n",
    "        self.resize = transforms.Resize((224, 224))\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = self.resize(img)\n",
    "        for aug in self.augmentations:\n",
    "            if torch.rand(1) < 0.5:\n",
    "                img = aug(img)\n",
    "        img = self.to_tensor(img)\n",
    "        img = self.normalize(img)\n",
    "        return img\n",
    "\n",
    "transform_train = RandomAugmentationPerImage()\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a465c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 5. PLOT SAMPLE & CLASS DISTRIBUTION ==========================\n",
    "def plot_class_distribution(labels, label_map, title='Class Distribution'):\n",
    "    counter = Counter(labels)\n",
    "    total = sum(counter.values())\n",
    "    print(f'--- {title} ---')\n",
    "    for i in range(len(label_map)):\n",
    "        count = counter.get(i, 0)\n",
    "        print(f'{i} ({label_map[i]}): {count} samples | {count / total * 100:.2f}%')\n",
    "    counts = [counter.get(i, 0) for i in range(len(label_map))]\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.pie(counts, labels=[label_map[i] for i in range(len(label_map))], autopct='%1.1f%%', startangle=140)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "original_labels = [label for _, label in train_dataset_raw.imgs]\n",
    "plot_class_distribution(original_labels, label_map, title='Original Train Distribution')\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 4))\n",
    "for i, ax in enumerate(axes):\n",
    "    img, label = train_dataset_raw[random.randint(0, len(train_dataset_raw) - 1)]\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(label_map[label])\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Sample Original Images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9543d48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 6. OVERSAMPLING ==========================\n",
    "targets = [train_dataset_raw.imgs[i][1] for i in range(len(train_dataset_raw.imgs))]\n",
    "class_counts = Counter(targets)\n",
    "max_count = max(class_counts.values()) * OVERSAMPLE_FACTOR\n",
    "weights_per_class = {cls: max_count / count for cls, count in class_counts.items()}\n",
    "sample_weights = np.array([weights_per_class[t] for t in targets])\n",
    "indices = np.random.choice(\n",
    "    len(targets),\n",
    "    size=len(targets) * OVERSAMPLE_FACTOR,\n",
    "    replace=True,\n",
    "    p=sample_weights / sample_weights.sum(),\n",
    ")\n",
    "\n",
    "class OversampledDataset(Dataset):\n",
    "    def __init__(self, base_dataset, indices, transform=None):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.indices = indices\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.base_dataset[self.indices[idx]]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "train_dataset_full = OversampledDataset(train_dataset_raw, indices, transform=transform_train)\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 4))\n",
    "for i, ax in enumerate(axes):\n",
    "    img, label = train_dataset_full[random.randint(0, len(train_dataset_full) - 1)]\n",
    "    img_np = img.permute(1, 2, 0).numpy()\n",
    "    denom = (img_np.max() - img_np.min())\n",
    "    img_np = (img_np - img_np.min()) / (denom if denom != 0 else 1.0)\n",
    "    ax.imshow(img_np)\n",
    "    ax.set_title(label_map[label])\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Sample Augmented Images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bfe777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 7. SPLIT TRAIN / VAL ==========================\n",
    "oversampled_imgs = [train_dataset_raw.imgs[i] for i in indices]\n",
    "paths, labels = zip(*oversampled_imgs)\n",
    "paths = np.array(paths)\n",
    "labels = np.array(labels)\n",
    "\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    paths, labels, test_size=0.3, stratify=labels, random_state=SEED\n",
    ")\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None):\n",
    "        self.paths = np.array(paths)\n",
    "        self.labels = np.array(labels)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx]).convert('RGB')\n",
    "        label = int(self.labels[idx])\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    CustomDataset(train_paths, train_labels, transform=transform_train),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    CustomDataset(val_paths, val_labels, transform=transform_val),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    ")\n",
    "\n",
    "test_paths = [p for p, _ in test_dataset.imgs]\n",
    "test_labels = [l for _, l in test_dataset.imgs]\n",
    "test_loader = DataLoader(\n",
    "    CustomDataset(test_paths, test_labels, transform=transform_val),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    ")\n",
    "\n",
    "plot_class_distribution(train_labels, label_map, title='Train Distribution After Oversampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9370e45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 8. CLASS WEIGHTS & LOSS ==========================\n",
    "train_labels_for_weights = train_labels.astype(int)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_labels_for_weights),\n",
    "    y=train_labels_for_weights,\n",
    ")\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, weight=None, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce = nn.CrossEntropyLoss(weight=self.weight, reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-ce)\n",
    "        loss = ((1 - pt) ** self.gamma) * ce\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "criterion = FocalLoss(gamma=2.0, weight=class_weights) if USE_FOCAL else nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# ========================== 9. EARLY STOPPING ==========================\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_f1 = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, f1):\n",
    "        if self.best_f1 is None:\n",
    "            self.best_f1 = f1\n",
    "            return\n",
    "        if f1 < self.best_f1 + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_f1 = f1\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e834e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 10. DENSENET121 MODEL ==========================\n",
    "# Kaggle often runs with Internet OFF by default.\n",
    "# To avoid runtime crashes, we only use pretrained weights if they are already cached locally.\n",
    "\n",
    "# Make this cell resilient if it's executed alone (e.g., kernel reset / run single cell)\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "if 'PRETRAINED' not in globals():\n",
    "    PRETRAINED = False\n",
    "    print('PRETRAINED was not defined; defaulting to PRETRAINED = False')\n",
    "if 'NUM_CLASSES' not in globals():\n",
    "    NUM_CLASSES = 9\n",
    "    print('NUM_CLASSES was not defined; defaulting to NUM_CLASSES = 9')\n",
    "\n",
    "DENSENET121_WEIGHT_FILENAME = \"densenet121-a639ec97.pth\"\n",
    "\n",
    "def _torchvision_weights_cached(filename: str) -> bool:\n",
    "    try:\n",
    "        hub_dir = Path(torch.hub.get_dir())\n",
    "    except Exception:\n",
    "        return False\n",
    "    return (hub_dir / \"checkpoints\" / filename).exists()\n",
    "\n",
    "class DenseNet121Model(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES, pretrained=PRETRAINED):\n",
    "        super().__init__()\n",
    "\n",
    "        if pretrained:\n",
    "            if not _torchvision_weights_cached(DENSENET121_WEIGHT_FILENAME):\n",
    "                print(\n",
    "                    \"PRETRAINED=True but DenseNet121 weights are not cached. \"\n",
    "                    \"Skipping download (likely no Internet) and using random init (weights=None).\"\n",
    "                )\n",
    "                self.densenet = models.densenet121(weights=None)\n",
    "            else:\n",
    "                try:\n",
    "                    weights = models.DenseNet121_Weights.DEFAULT\n",
    "                    self.densenet = models.densenet121(weights=weights)\n",
    "                    print(\"Loaded ImageNet pretrained weights (DenseNet121) from cache.\")\n",
    "                except Exception as e:\n",
    "                    print(\"Warning: failed to load cached pretrained weights; using random init. Error:\", repr(e))\n",
    "                    self.densenet = models.densenet121(weights=None)\n",
    "        else:\n",
    "            self.densenet = models.densenet121(weights=None)\n",
    "\n",
    "        for i, child in enumerate(self.densenet.features.children()):\n",
    "            if i < 6:\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "        num_features = self.densenet.classifier.in_features\n",
    "        self.densenet.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.densenet(x)\n",
    "\n",
    "model = DenseNet121Model(num_classes=NUM_CLASSES).to(device)\n",
    "print(f\"Model loaded on {device}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecae524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 11. TRAIN / EVAL FUNCTIONS ==========================\n",
    "# TPU (XLA) support: use xm.optimizer_step on TPU\n",
    "try:\n",
    "    import torch_xla.core.xla_model as xm  # type: ignore\n",
    "    _HAS_XLA = True\n",
    "except Exception:\n",
    "    xm = None\n",
    "    _HAS_XLA = False\n",
    "\n",
    "_IS_XLA_DEVICE = _HAS_XLA and ('xla' in str(device))\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device, epoch):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    loop = tqdm(enumerate(loader), total=len(loader), desc=f'Epoch {epoch} [TRAIN]')\n",
    "    for i, (imgs, labels) in loop:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        if _IS_XLA_DEVICE:\n",
    "            xm.optimizer_step(optimizer, barrier=True)\n",
    "            xm.mark_step()\n",
    "        else:\n",
    "            optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        preds = outputs.argmax(1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        loop.set_postfix(loss=running_loss / (i + 1), acc=correct / total)\n",
    "    return running_loss / len(loader), correct / total\n",
    "\n",
    "def eval_one_epoch(model, loader, criterion, device, epoch):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(enumerate(loader), total=len(loader), desc=f'Epoch {epoch} [VAL]')\n",
    "        for i, (imgs, labels) in loop:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            preds = outputs.argmax(1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            loop.set_postfix(loss=running_loss / (i + 1), acc=correct / total)\n",
    "    macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    return running_loss / len(loader), correct / total, macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3370a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 12. TRAINING LOOP ==========================\n",
    "# TPU (XLA) safe checkpoint save\n",
    "try:\n",
    "    import torch_xla.core.xla_model as xm  # type: ignore\n",
    "    _HAS_XLA = True\n",
    "except Exception:\n",
    "    xm = None\n",
    "    _HAS_XLA = False\n",
    "\n",
    "_IS_XLA_DEVICE = _HAS_XLA and ('xla' in str(device))\n",
    "\n",
    "def _save_ckpt(state_dict, path):\n",
    "    if _IS_XLA_DEVICE:\n",
    "        xm.save(state_dict, str(path))\n",
    "    else:\n",
    "        torch.save(state_dict, path)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_MAX)\n",
    "early_stopper = EarlyStopping(patience=PATIENCE)\n",
    "\n",
    "best_f1 = 0.0\n",
    "best_epoch = 0\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': [], 'f1': []}\n",
    "\n",
    "with open(LOG_CSV, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['epoch', 'train_loss', 'train_acc', 'val_loss', 'val_acc', 'macro_f1'])\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device, epoch)\n",
    "    val_loss, val_acc, val_macro_f1 = eval_one_epoch(model, val_loader, criterion, device, epoch)\n",
    "\n",
    "    scheduler.step()\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['f1'].append(val_macro_f1)\n",
    "\n",
    "    with open(LOG_CSV, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([epoch, train_loss, train_acc, val_loss, val_acc, val_macro_f1])\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        ckpt_path = CKPT_DIR / f'model_epoch_{epoch}.pt'\n",
    "        _save_ckpt(model.state_dict(), ckpt_path)\n",
    "        print(' Saved checkpoint:', ckpt_path)\n",
    "\n",
    "    if val_macro_f1 > best_f1:\n",
    "        best_f1 = val_macro_f1\n",
    "        best_epoch = epoch\n",
    "        best_path = BEST_DIR / 'best_model_densenet121.pt'\n",
    "        _save_ckpt(model.state_dict(), best_path)\n",
    "        print(f' Best model updated at epoch {epoch} | F1={best_f1:.4f}')\n",
    "\n",
    "    print(\n",
    "        f'Epoch {epoch}/{NUM_EPOCHS} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | '\n",
    "        f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | Macro F1: {val_macro_f1:.4f}'\n",
    "    )\n",
    "\n",
    "    early_stopper(val_macro_f1)\n",
    "    if early_stopper.early_stop:\n",
    "        print('>>> Early stopping triggered. Stopping training.')\n",
    "        break\n",
    "\n",
    "print('\\nTraining completed. Best Epoch =', best_epoch, '| Best F1 =', best_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0635385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 13. PLOT METRICS ==========================\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history['train_acc'], label='Train Acc')\n",
    "plt.plot(history['val_acc'], label='Val Acc')\n",
    "plt.title('Accuracy Curve')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history['f1'], label='Macro F1')\n",
    "plt.title('Macro F1 Curve')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plot_path = RESULT_DIR / 'training_curves_densenet121.png'\n",
    "plt.savefig(plot_path)\n",
    "print('Saved:', plot_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0ec80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 14. CONFUSION MATRIX & TEST ==========================\n",
    "best_model_path = BEST_DIR / 'best_model_densenet121.pt'\n",
    "if best_model_path.exists():\n",
    "    # TPU-safe: load weights onto CPU first\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location='cpu'))\n",
    "    print('Loaded best model from', best_model_path)\n",
    "else:\n",
    "    print('Best model not found yet at:', best_model_path)\n",
    "\n",
    "def plot_confusion(loader, title, save_path):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            preds = outputs.argmax(1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=label_map.values(), yticklabels=label_map.values(), cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True')\n",
    "    plt.xlabel('Pred')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    print('Saved:', save_path)\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion(val_loader, 'Validation Confusion Matrix (DenseNet121)', RESULT_DIR / 'val_conf_matrix_densenet121.png')\n",
    "plot_confusion(test_loader, 'Test Confusion Matrix (DenseNet121)', RESULT_DIR / 'test_conf_matrix_densenet121.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15ad2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 15. DETAILED EVALUATION ==========================\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "        preds = outputs.argmax(1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "\n",
    "report = classification_report(all_labels, all_preds, target_names=list(label_map.values()))\n",
    "print('\\nClassification Report (DenseNet121):\\n', report)\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=label_map.values(), yticklabels=label_map.values(), cmap='Blues')\n",
    "plt.title('Confusion Matrix (Validation - DenseNet121)')\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Pred')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "counter = Counter(all_labels)\n",
    "print('\\nNumber of samples per class in validation set:')\n",
    "for i, name in label_map.items():\n",
    "    print(f'{name}: {counter[i]}')\n",
    "\n",
    "y_test_bin = label_binarize(all_labels, classes=list(range(NUM_CLASSES)))\n",
    "y_score_bin = label_binarize(all_preds, classes=list(range(NUM_CLASSES)))\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "for i in range(NUM_CLASSES):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score_bin[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{label_map[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve per Class (Validation - DenseNet121)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
